{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.svm import SVC\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_validate\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, ConfusionMatrixDisplay, make_scorer\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import time\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def cross_validate_model(model, X, y, cv, bivariate, printer=True):\n",
    "    \"\"\"Perform cross-validation with a Random Forest and print metrics if printer=True\"\"\"\n",
    "    if not bivariate:\n",
    "        scoring = {\n",
    "            'accuracy': 'accuracy',\n",
    "            'precision': make_scorer(precision_score, average='weighted', zero_division=1),\n",
    "            'recall': make_scorer(recall_score, average='weighted', zero_division=1),\n",
    "            'f1': make_scorer(f1_score, average='weighted', zero_division=1)\n",
    "        }\n",
    "    else:\n",
    "        scoring = {\n",
    "            'accuracy': 'accuracy',\n",
    "            'precision': make_scorer(precision_score, average='binary', zero_division=1),\n",
    "            'recall': make_scorer(recall_score, average='binary', zero_division=1),\n",
    "            'f1': make_scorer(f1_score, average='binary', zero_division=1)\n",
    "        }\n",
    "    start = time.time()\n",
    "    results = cross_validate(model, X, y, cv=cv, scoring=scoring)\n",
    "    end = time.time()\n",
    "\n",
    "    if printer:\n",
    "        print(f\"Accuracy: {results['test_accuracy'].mean():.4f}\")\n",
    "        print(f\"Precision: {results['test_precision'].mean():.4f}\")\n",
    "        print(f\"Recall: {results['test_recall'].mean():.4f}\")\n",
    "        print(f\"F1 Score: {results['test_f1'].mean():.4f}\")\n",
    "        print(\"Prediction time: \", end - start)\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "def scale_data(X_train, X_test):\n",
    "    \"\"\"Scale only numerical features using StandardScaler.\"\"\"\n",
    "    numeric_cols = X_train.select_dtypes(include=['number']).columns  \n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = X_train.copy()\n",
    "    X_test_scaled = X_test.copy()\n",
    "    X_train_scaled[numeric_cols] = scaler.fit_transform(X_train[numeric_cols])\n",
    "    X_test_scaled[numeric_cols] = scaler.transform(X_test[numeric_cols])\n",
    "    return X_train_scaled, X_test_scaled\n",
    "\n",
    "\n",
    "def get_dummies_all(X_train, X_test):\n",
    "    \"\"\"Converts all categorical variables in a DataFrame into dummy (one-hot encoded) variables.\"\"\"\n",
    "    categorical_cols = X_train.select_dtypes(include=['object', 'category']).columns  # Select categorical columns\n",
    "    X_train_encoded = pd.get_dummies(X_train, columns=categorical_cols, drop_first=False)  # One-hot encode them\n",
    "    categorical_cols = X_test.select_dtypes(include=['object', 'category']).columns  # Select categorical columns\n",
    "    X_test_encoded = pd.get_dummies(X_test, columns=categorical_cols, drop_first=False)  # One-hot encode them\n",
    "    return X_train_encoded, X_test_encoded\n",
    "\n",
    "\n",
    "def oversampling(X, y):\n",
    "    \"\"\"Overamples the data to get equal proportions of target\"\"\"\n",
    "    ros = RandomOverSampler(random_state=42)\n",
    "    X_train_resampled, y_train_resampled = ros.fit_resample(X, y)\n",
    "    print(f\"Original class distribution: {y.value_counts()}\")\n",
    "    print(f\"Resampled class distribution: {pd.Series(y_train_resampled).value_counts()}\")\n",
    "    return X_train_resampled, y_train_resampled\n",
    "\n",
    "\n",
    "def hyperparameterTuning(X, y, cv, bivariate):\n",
    "    \"\"\"Searches for the best hyperparameters from a set of values\"\"\"\n",
    "    param_grid = {\n",
    "            'max_depth': [None, 10, 20],\n",
    "            'n_estimators': [30, 50, 100],\n",
    "            'min_samples_leaf': [1, 5, 10],\n",
    "            'min_samples_split': [2, 5, 10]\n",
    "        }\n",
    "\n",
    "    if bivariate == True:\n",
    "        scoring = {\n",
    "        'accuracy': 'accuracy',\n",
    "        'precision_weighted': make_scorer(precision_score, average='macro', zero_division=1),\n",
    "        'recall_weighted': make_scorer(recall_score, average='macro', zero_division=1),\n",
    "        'f1_weighted': make_scorer(f1_score, average='macro', zero_division=1)\n",
    "        }\n",
    "\n",
    "        start = time.time()\n",
    "        rf = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "        grid_search = GridSearchCV(rf, param_grid, cv=cv, scoring=scoring, refit='accuracy', n_jobs=-1)\n",
    "        grid_search.fit(X, y)\n",
    "        print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "        print(f\"Best cross-validation accuracy: {grid_search.cv_results_['mean_test_accuracy'][grid_search.best_index_]:.4f}\")\n",
    "        print(f\"Best cross-validation precision: {grid_search.cv_results_['mean_test_precision_weighted'][grid_search.best_index_]:.4f}\")\n",
    "        print(f\"Best cross-validation recall: {grid_search.cv_results_['mean_test_recall_weighted'][grid_search.best_index_]:.4f}\")\n",
    "        print(f\"Best cross-validation F1 Score: {grid_search.cv_results_['mean_test_f1_weighted'][grid_search.best_index_]:.4f}\")\n",
    "        print(\"Time for Hypertuning: \", time.time()-start)\n",
    "    else:\n",
    "        scoring = {\n",
    "        'accuracy': 'accuracy',\n",
    "        'precision_weighted': make_scorer(precision_score, average='weighted', zero_division=1),\n",
    "        'recall_weighted': make_scorer(recall_score, average='weighted', zero_division=1),\n",
    "        'f1_weighted': make_scorer(f1_score, average='weighted', zero_division=1)\n",
    "        }\n",
    "        start = time.time()\n",
    "        rf = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "        grid_search = GridSearchCV(rf, param_grid, cv=cv, scoring=scoring, refit='accuracy', n_jobs=-1)\n",
    "        grid_search.fit(X, y)\n",
    "        print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "        print(f\"Best cross-validation accuracy: {grid_search.cv_results_['mean_test_accuracy'][grid_search.best_index_]:.4f}\")\n",
    "        print(f\"Best cross-validation precision: {grid_search.cv_results_['mean_test_precision_weighted'][grid_search.best_index_]:.4f}\")\n",
    "        print(f\"Best cross-validation recall: {grid_search.cv_results_['mean_test_recall_weighted'][grid_search.best_index_]:.4f}\")\n",
    "        print(f\"Best cross-validation F1 Score: {grid_search.cv_results_['mean_test_f1_weighted'][grid_search.best_index_]:.4f}\")\n",
    "        print(\"Time for Hypertuning: \", time.time()-start)\n",
    "\n",
    "    best_model = grid_search.best_estimator_  # Best trained model\n",
    "    best_params = grid_search.best_params_    # Best hyperparameters\n",
    "    return best_model, best_params \n",
    "\n",
    "\n",
    "def predict_on_testset(best_model, X_test, y_test):\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average=\"macro\", zero_division=1)\n",
    "    recall = recall_score(y_test, y_pred, average=\"macro\", zero_division=1)\n",
    "    f1 = f1_score(y_test, y_pred, average=\"macro\", zero_division=1)\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------\n",
      "-------------------------------------- CREDIT CARD DEFAULT -----------------------------------\n",
      "----------------------------------------------------------------------------------------------\n",
      "\n",
      "-------------------------------------- ORIGINAL DATASET --------------------------------------\n",
      "----------------------------------------------------------------------------------------------\n",
      "Original class distribution: default_payment_next_month\n",
      "0    18538\n",
      "1     5212\n",
      "Name: count, dtype: int64\n",
      "Resampled class distribution: default_payment_next_month\n",
      "1    18538\n",
      "0    18538\n",
      "Name: count, dtype: int64\n",
      "CCD:\n",
      "Accuracy: 0.8181\n",
      "Precision: 0.6517\n",
      "Recall: 0.3705\n",
      "F1 Score: 0.4721\n",
      "Prediction time:  11.339915037155151\n",
      "----------------------------------------------------------------------------------------------\n",
      "CCD - Oversampled:\n",
      "Accuracy: 0.9409\n",
      "Precision: 0.9072\n",
      "Recall: 0.9822\n",
      "F1 Score: 0.9432\n",
      "Prediction time:  15.820959091186523\n",
      "----------------------------------------------------------------------------------------------\n",
      "CCD - Hyperparameter Tuning:\n",
      "Best parameters: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Best cross-validation accuracy: 0.9409\n",
      "Best cross-validation precision: 0.9441\n",
      "Best cross-validation recall: 0.9409\n",
      "Best cross-validation F1 Score: 0.9408\n",
      "Time for Hypertuning:  459.88489174842834\n",
      "----------------------------------------------------------------------------------------------\n",
      "CCD - Predict on testset:\n",
      "Accuracy: 0.8064\n",
      "Precision: 0.7253\n",
      "Recall: 0.6746\n",
      "F1 Score: 0.6921\n",
      "\n",
      "----------------------------------- AFTER MICROAGGREGATION -----------------------------------\n",
      "----------------------------------------------------------------------------------------------\n",
      "CCD - mdav\n",
      "Original class distribution: default_payment_next_month\n",
      "0    23364\n",
      "1     6636\n",
      "Name: count, dtype: int64\n",
      "Resampled class distribution: default_payment_next_month\n",
      "1    23364\n",
      "0    23364\n",
      "Name: count, dtype: int64\n",
      "CCD MDAV:\n",
      "Accuracy: 0.8146\n",
      "Precision: 0.6676\n",
      "Recall: 0.3341\n",
      "F1 Score: 0.4413\n",
      "Prediction time:  19.451128482818604\n",
      "----------------------------------------------------------------------------------------------\n",
      "CCD MDAV - Oversampled:\n",
      "Accuracy: 0.5318\n",
      "Precision: 0.5181\n",
      "Recall: 0.9851\n",
      "F1 Score: 0.6787\n",
      "Prediction time:  22.969454526901245\n",
      "----------------------------------------------------------------------------------------------\n",
      "CCD MDAV - Hyperparameter Tuning:\n",
      "Best parameters: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 30}\n",
      "Best cross-validation accuracy: 0.5543\n",
      "Best cross-validation precision: 0.6075\n",
      "Best cross-validation recall: 0.5543\n",
      "Best cross-validation F1 Score: 0.4427\n",
      "Time for Hypertuning:  700.8873779773712\n",
      "----------------------------------------------------------------------------------------------\n",
      "CCD MDAV - Predict on testset:\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The feature names should match those that were passed during fit.\nFeature names seen at fit time, yet now missing:\n- ID\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 56\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m----------------------------------------------------------------------------------------------\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCCD MDAV - Predict on testset:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 56\u001b[0m \u001b[43mpredict_on_testset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbest_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCCD - PCA\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     60\u001b[0m CCD_train_pca \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:/Users/ameli/OneDrive/Studium/TU Wien/WS2024/ML/Exercise 3/modifiedDatasets/CCD_pca.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[3], line 111\u001b[0m, in \u001b[0;36mpredict_on_testset\u001b[1;34m(best_model, X_test, y_test)\u001b[0m\n\u001b[0;32m    110\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict_on_testset\u001b[39m(best_model, X_test, y_test):\n\u001b[1;32m--> 111\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mbest_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    112\u001b[0m     accuracy \u001b[38;5;241m=\u001b[39m accuracy_score(y_test, y_pred)\n\u001b[0;32m    113\u001b[0m     precision \u001b[38;5;241m=\u001b[39m precision_score(y_test, y_pred, average\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmacro\u001b[39m\u001b[38;5;124m\"\u001b[39m, zero_division\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Python3107\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:904\u001b[0m, in \u001b[0;36mForestClassifier.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    883\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[0;32m    884\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    885\u001b[0m \u001b[38;5;124;03m    Predict class for X.\u001b[39;00m\n\u001b[0;32m    886\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    902\u001b[0m \u001b[38;5;124;03m        The predicted classes.\u001b[39;00m\n\u001b[0;32m    903\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 904\u001b[0m     proba \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_proba\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    906\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    907\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_\u001b[38;5;241m.\u001b[39mtake(np\u001b[38;5;241m.\u001b[39margmax(proba, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32mc:\\Python3107\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:946\u001b[0m, in \u001b[0;36mForestClassifier.predict_proba\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    944\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    945\u001b[0m \u001b[38;5;66;03m# Check data\u001b[39;00m\n\u001b[1;32m--> 946\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_X_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    948\u001b[0m \u001b[38;5;66;03m# Assign chunk of trees to jobs\u001b[39;00m\n\u001b[0;32m    949\u001b[0m n_jobs, _, _ \u001b[38;5;241m=\u001b[39m _partition_estimators(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_estimators, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs)\n",
      "File \u001b[1;32mc:\\Python3107\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:638\u001b[0m, in \u001b[0;36mBaseForest._validate_X_predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    635\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    636\u001b[0m     ensure_all_finite \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 638\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mvalidate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    639\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    640\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    641\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDTYPE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    642\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    643\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    644\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    645\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    646\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m issparse(X) \u001b[38;5;129;01mand\u001b[39;00m (X\u001b[38;5;241m.\u001b[39mindices\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m np\u001b[38;5;241m.\u001b[39mintc \u001b[38;5;129;01mor\u001b[39;00m X\u001b[38;5;241m.\u001b[39mindptr\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m np\u001b[38;5;241m.\u001b[39mintc):\n\u001b[0;32m    647\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo support for np.int64 index based sparse matrices\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Python3107\\lib\\site-packages\\sklearn\\utils\\validation.py:2919\u001b[0m, in \u001b[0;36mvalidate_data\u001b[1;34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[0m\n\u001b[0;32m   2835\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvalidate_data\u001b[39m(\n\u001b[0;32m   2836\u001b[0m     _estimator,\n\u001b[0;32m   2837\u001b[0m     \u001b[38;5;241m/\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2843\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params,\n\u001b[0;32m   2844\u001b[0m ):\n\u001b[0;32m   2845\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Validate input data and set or check feature names and counts of the input.\u001b[39;00m\n\u001b[0;32m   2846\u001b[0m \n\u001b[0;32m   2847\u001b[0m \u001b[38;5;124;03m    This helper function should be used in an estimator that requires input\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2917\u001b[0m \u001b[38;5;124;03m        validated.\u001b[39;00m\n\u001b[0;32m   2918\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 2919\u001b[0m     \u001b[43m_check_feature_names\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_estimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2920\u001b[0m     tags \u001b[38;5;241m=\u001b[39m get_tags(_estimator)\n\u001b[0;32m   2921\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m tags\u001b[38;5;241m.\u001b[39mtarget_tags\u001b[38;5;241m.\u001b[39mrequired:\n",
      "File \u001b[1;32mc:\\Python3107\\lib\\site-packages\\sklearn\\utils\\validation.py:2777\u001b[0m, in \u001b[0;36m_check_feature_names\u001b[1;34m(estimator, X, reset)\u001b[0m\n\u001b[0;32m   2774\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m missing_names \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m unexpected_names:\n\u001b[0;32m   2775\u001b[0m     message \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeature names must be in the same order as they were in fit.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 2777\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(message)\n",
      "\u001b[1;31mValueError\u001b[0m: The feature names should match those that were passed during fit.\nFeature names seen at fit time, yet now missing:\n- ID\n"
     ]
    }
   ],
   "source": [
    "print(\"----------------------------------------------------------------------------------------------\")\n",
    "print(\"-------------------------------------- CREDIT CARD DEFAULT -----------------------------------\")\n",
    "print(\"----------------------------------------------------------------------------------------------\")\n",
    "print(\"\")\n",
    "\n",
    "print(\"-------------------------------------- ORIGINAL DATASET --------------------------------------\")\n",
    "print(\"----------------------------------------------------------------------------------------------\")\n",
    "CCD_train = pd.read_csv(\"C:/Users/ameli/OneDrive/Studium/TU Wien/WS2024/ML/Exercise 3/Datasets/CCD_train.csv\")\n",
    "CCD_test = pd.read_csv(\"C:/Users/ameli/OneDrive/Studium/TU Wien/WS2024/ML/Exercise 3/Datasets/CCD_test.csv\")\n",
    "X_train = CCD_train.drop('default_payment_next_month', axis=1); y_train = CCD_train['default_payment_next_month']\n",
    "X_test = CCD_test.drop('default_payment_next_month', axis=1); y_test = CCD_test['default_payment_next_month']\n",
    "X_train_oversampled, y_train_oversampled = oversampling(X_train, y_train)\n",
    "\n",
    "print(\"CCD:\")\n",
    "rf = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "cross_validate_model(rf, X_train, y_train, cv=5, bivariate = True)\n",
    "\n",
    "print(\"----------------------------------------------------------------------------------------------\")\n",
    "print(\"CCD - Oversampled:\")\n",
    "rf = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "cross_validate_model(rf, X_train_oversampled, y_train_oversampled, cv=5, bivariate = True)\n",
    "\n",
    "print(\"----------------------------------------------------------------------------------------------\")\n",
    "print(\"CCD - Hyperparameter Tuning:\")\n",
    "best_model, best_params = hyperparameterTuning(X_train_oversampled, y_train_oversampled, cv=5, bivariate = True)\n",
    "\n",
    "print(\"----------------------------------------------------------------------------------------------\")\n",
    "print(\"CCD - Predict on testset:\")\n",
    "predict_on_testset(best_model, X_test, y_test)\n",
    "\n",
    "\n",
    "print(\"\")\n",
    "print(\"----------------------------------- AFTER MICROAGGREGATION -----------------------------------\")\n",
    "print(\"----------------------------------------------------------------------------------------------\")\n",
    "\n",
    "print(\"CCD - mdav\")\n",
    "CCD_train_mdav = pd.read_csv(\"C:/Users/ameli/OneDrive/Studium/TU Wien/WS2024/ML/Exercise 3/modifiedDatasets/CCD_mdav.csv\")\n",
    "X_train_mdav = CCD_train_mdav.drop('default_payment_next_month', axis=1);  y_train_mdav = CCD_train_mdav['default_payment_next_month']\n",
    "X_train_mdav_oversampled, y_train_mdav_oversampled = oversampling(X_train_mdav, y_train_mdav)\n",
    "\n",
    "print(\"CCD MDAV:\")\n",
    "rf = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "cross_validate_model(rf, X_train_mdav, y_train_mdav, cv=5, bivariate = True)\n",
    "\n",
    "print(\"----------------------------------------------------------------------------------------------\")\n",
    "print(\"CCD MDAV - Oversampled:\")\n",
    "rf = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "cross_validate_model(rf, X_train_mdav_oversampled, y_train_mdav_oversampled, cv=5, bivariate = True)\n",
    "\n",
    "print(\"----------------------------------------------------------------------------------------------\")\n",
    "print(\"CCD MDAV - Hyperparameter Tuning:\")\n",
    "best_model, best_params = hyperparameterTuning(X_train_mdav_oversampled, y_train_mdav_oversampled, cv=5, bivariate = True)\n",
    "\n",
    "print(\"----------------------------------------------------------------------------------------------\")\n",
    "print(\"CCD MDAV - Predict on testset:\")\n",
    "predict_on_testset(best_model, X_test, y_test)\n",
    "\n",
    "\n",
    "print(\"CCD - PCA\")\n",
    "CCD_train_pca = pd.read_csv(\"C:/Users/ameli/OneDrive/Studium/TU Wien/WS2024/ML/Exercise 3/modifiedDatasets/CCD_pca.csv\")\n",
    "X_train_pca = CCD_train_pca.drop('default_payment_next_month', axis=1);  y_train_pca = CCD_train_pca['default_payment_next_month']\n",
    "X_train_pca_oversampled, y_train_pca_oversampled = oversampling(X_train_pca, y_train_pca)\n",
    "\n",
    "print(\"CCD PCA:\")\n",
    "rf = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "cross_validate_model(rf, X_train_pca, y_train_pca, cv=5, bivariate=True)\n",
    "\n",
    "print(\"----------------------------------------------------------------------------------------------\")\n",
    "print(\"CCD PCA - Oversampled:\")\n",
    "rf = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "cross_validate_model(rf, X_train_pca_oversampled, y_train_pca_oversampled, cv=5, bivariate=True)\n",
    "\n",
    "print(\"----------------------------------------------------------------------------------------------\")\n",
    "print(\"CCD PCA - Hyperparameter Tuning:\")\n",
    "best_model, best_params = hyperparameterTuning(X_train_pca_oversampled, y_train_pca_oversampled, cv=5, bivariate=True)\n",
    "\n",
    "print(\"----------------------------------------------------------------------------------------------\")\n",
    "print(\"CCD PCA - Predict on testset:\")\n",
    "predict_on_testset(best_model, X_test, y_test)\n",
    "\n",
    "\n",
    "print(\"CCD - onedims\")\n",
    "CCD_train_onedims = pd.read_csv(\"C:/Users/ameli/OneDrive/Studium/TU Wien/WS2024/ML/Exercise 3/modifiedDatasets/CCD_onedims.csv\")\n",
    "X_train_onedims = CCD_train_onedims.drop('default_payment_next_month', axis=1);  y_train_onedims = CCD_train_onedims['default_payment_next_month']\n",
    "X_train_onedims_oversampled, y_train_onedims_oversampled = oversampling(X_train_onedims, y_train_onedims)\n",
    "\n",
    "print(\"CCD onedims:\")\n",
    "rf = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "cross_validate_model(rf, X_train_onedims, y_train_onedims, cv=5, bivariate=True)\n",
    "\n",
    "print(\"----------------------------------------------------------------------------------------------\")\n",
    "print(\"CCD onedims - Oversampled:\")\n",
    "rf = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "cross_validate_model(rf, X_train_onedims_oversampled, y_train_onedims_oversampled, cv=5, bivariate=True)\n",
    "\n",
    "print(\"----------------------------------------------------------------------------------------------\")\n",
    "print(\"CCD onedims - Hyperparameter Tuning:\")\n",
    "best_model, best_params = hyperparameterTuning(X_train_onedims_oversampled, y_train_onedims_oversampled, cv=5, bivariate=True)\n",
    "\n",
    "print(\"----------------------------------------------------------------------------------------------\")\n",
    "print(\"CCD onedims - Predict on testset:\")\n",
    "predict_on_testset(best_model, X_test, y_test)\n",
    "\n",
    "print(\"\")\n",
    "print(\"----------------------------------- AFTER Global Transformation -----------------------------------\")\n",
    "print(\"----------------------------------------------------------------------------------------------\")\n",
    "CCD_train = pd.read_csv(\"data/CCD_train_GT.csv\")\n",
    "CCD_test = pd.read_csv(\"data/CCD_test_GT.csv\")\n",
    "X_train = CCD_train.drop('default_payment_next_month', axis=1); y_train = CCD_train['default_payment_next_month']\n",
    "X_test = CCD_test.drop('default_payment_next_month', axis=1); y_test = CCD_test['default_payment_next_month']\n",
    "X_train, X_test = get_dummies_all(X_train, X_test)\n",
    "X_train_oversampled, y_train_oversampled = oversampling(X_train, y_train)\n",
    "\n",
    "print(\"CCD Global Transformation:\")\n",
    "rf = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "cross_validate_model(rf, X_train, y_train, cv=3, bivariate = True)\n",
    "\n",
    "print(\"----------------------------------------------------------------------------------------------\")\n",
    "print(\"CCD Global Transformation - Oversampled:\")\n",
    "rf = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "cross_validate_model(rf, X_train_oversampled, y_train_oversampled, cv=3, bivariate = True)\n",
    "\n",
    "print(\"----------------------------------------------------------------------------------------------\")\n",
    "print(\"CCD Global Transformation- Hyperparameter Tuning:\")\n",
    "best_model, best_params = hyperparameterTuning(X_train, y_train, cv=3, bivariate = True)\n",
    "\n",
    "print(\"----------------------------------------------------------------------------------------------\")\n",
    "print(\"CCD Global Transformation - Predict on testset:\")\n",
    "predict_on_testset(best_model, X_test, y_test)\n",
    "\n",
    "\n",
    "print(\"\")\n",
    "print(\"----------------------------------- AFTER LOCAL Transformation -----------------------------------\")\n",
    "print(\"----------------------------------------------------------------------------------------------\")\n",
    "CCD_train = pd.read_csv(\"data/CCD_train_LT.csv\")\n",
    "CCD_test = pd.read_csv(\"data/CCD_test_LT.csv\")\n",
    "X_train = CCD_train.drop('default_payment_next_month', axis=1); y_train = CCD_train['default_payment_next_month']\n",
    "X_test = CCD_test.drop('default_payment_next_month', axis=1); y_test = CCD_test['default_payment_next_month']\n",
    "X_train, X_test = get_dummies_all(X_train, X_test)\n",
    "X_train_oversampled, y_train_oversampled = oversampling(X_train, y_train)\n",
    "\n",
    "print(\"CCD Global Transformation:\")\n",
    "rf = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "cross_validate_model(rf, X_train, y_train, cv=3, bivariate = True)\n",
    "\n",
    "print(\"----------------------------------------------------------------------------------------------\")\n",
    "print(\"CCD Global Transformation - Oversampled:\")\n",
    "rf = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "cross_validate_model(rf, X_train_oversampled, y_train_oversampled, cv=3, bivariate = True)\n",
    "\n",
    "print(\"----------------------------------------------------------------------------------------------\")\n",
    "print(\"CCD Global Transformation- Hyperparameter Tuning:\")\n",
    "best_model, best_params = hyperparameterTuning(X_train, y_train, cv=3, bivariate = True)\n",
    "\n",
    "print(\"----------------------------------------------------------------------------------------------\")\n",
    "print(\"CCD Global Transformation - Predict on testset:\")\n",
    "predict_on_testset(best_model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------\n",
      "------------------------------------ PIMA INDIANS DIABETES  ----------------------------------\n",
      "----------------------------------------------------------------------------------------------\n",
      "\n",
      "-------------------------------------- ORIGINAL DATASET --------------------------------------\n",
      "----------------------------------------------------------------------------------------------\n",
      "Original class distribution: Outcome\n",
      "0    388\n",
      "1    208\n",
      "Name: count, dtype: int64\n",
      "Resampled class distribution: Outcome\n",
      "1    388\n",
      "0    388\n",
      "Name: count, dtype: int64\n",
      "PID:\n",
      "Accuracy: 0.7600\n",
      "Precision: 0.7077\n",
      "Recall: 0.5815\n",
      "F1 Score: 0.6312\n",
      "Prediction time:  1.3368866443634033\n",
      "----------------------------------------------------------------------------------------------\n",
      "PID - Oversampled:\n",
      "Accuracy: 0.8621\n",
      "Precision: 0.8390\n",
      "Recall: 0.9000\n",
      "F1 Score: 0.8673\n",
      "Prediction time:  1.2542872428894043\n",
      "----------------------------------------------------------------------------------------------\n",
      "PID - Hyperparameter Tuning:\n",
      "Best parameters: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Best cross-validation accuracy: 0.8621\n",
      "Best cross-validation precision: 0.8663\n",
      "Best cross-validation recall: 0.8622\n",
      "Best cross-validation F1 Score: 0.8617\n",
      "Time for Hypertuning:  17.88666319847107\n",
      "----------------------------------------------------------------------------------------------\n",
      "PID - Predict on testset:\n",
      "\n",
      "Test Set Performance:\n",
      "Accuracy: 0.7326\n",
      "Precision: 0.7065\n",
      "Recall: 0.7095\n",
      "F1 Score: 0.7079\n",
      "\n",
      "----------------------------------- AFTER MICROAGGREGATION -----------------------------------\n",
      "----------------------------------------------------------------------------------------------\n",
      "PID - mdav\n",
      "Original class distribution: Outcome\n",
      "0    388\n",
      "1    208\n",
      "Name: count, dtype: int64\n",
      "Resampled class distribution: Outcome\n",
      "1    388\n",
      "0    388\n",
      "Name: count, dtype: int64\n",
      "PID MDAV:\n",
      "Accuracy: 0.7618\n",
      "Precision: 0.7023\n",
      "Recall: 0.6057\n",
      "F1 Score: 0.6434\n",
      "Prediction time:  1.308363437652588\n",
      "----------------------------------------------------------------------------------------------\n",
      "PID MDAV - Oversampled:\n",
      "Accuracy: 0.8570\n",
      "Precision: 0.8293\n",
      "Recall: 0.9026\n",
      "F1 Score: 0.8633\n",
      "Prediction time:  1.371941089630127\n",
      "----------------------------------------------------------------------------------------------\n",
      "PID MDAV - Hyperparameter Tuning:\n",
      "Best parameters: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 30}\n",
      "Best cross-validation accuracy: 0.8596\n",
      "Best cross-validation precision: 0.8637\n",
      "Best cross-validation recall: 0.8597\n",
      "Best cross-validation F1 Score: 0.8591\n",
      "Time for Hypertuning:  19.850064277648926\n",
      "----------------------------------------------------------------------------------------------\n",
      "PID MDAV - Predict on testset:\n",
      "\n",
      "Test Set Performance:\n",
      "Accuracy: 0.7384\n",
      "Precision: 0.7114\n",
      "Recall: 0.7063\n",
      "F1 Score: 0.7086\n",
      "PID - PCA\n",
      "Original class distribution: Outcome\n",
      "0    388\n",
      "1    208\n",
      "Name: count, dtype: int64\n",
      "Resampled class distribution: Outcome\n",
      "1    388\n",
      "0    388\n",
      "Name: count, dtype: int64\n",
      "PID PCA:\n",
      "Accuracy: 0.7618\n",
      "Precision: 0.7166\n",
      "Recall: 0.5578\n",
      "F1 Score: 0.6196\n",
      "Prediction time:  1.3332958221435547\n",
      "----------------------------------------------------------------------------------------------\n",
      "PID PCA - Oversampled:\n",
      "Accuracy: 0.8467\n",
      "Precision: 0.8193\n",
      "Recall: 0.8923\n",
      "F1 Score: 0.8521\n",
      "Prediction time:  1.25246262550354\n",
      "----------------------------------------------------------------------------------------------\n",
      "PID PCA - Hyperparameter Tuning:\n",
      "Best parameters: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 30}\n",
      "Best cross-validation accuracy: 0.8518\n",
      "Best cross-validation precision: 0.8584\n",
      "Best cross-validation recall: 0.8520\n",
      "Best cross-validation F1 Score: 0.8512\n",
      "Time for Hypertuning:  18.743412733078003\n",
      "----------------------------------------------------------------------------------------------\n",
      "PID PCA - Predict on testset:\n",
      "\n",
      "Test Set Performance:\n",
      "Accuracy: 0.7035\n",
      "Precision: 0.6699\n",
      "Recall: 0.6524\n",
      "F1 Score: 0.6575\n",
      "PID - onedims\n",
      "Original class distribution: Outcome\n",
      "0    388\n",
      "1    208\n",
      "Name: count, dtype: int64\n",
      "Resampled class distribution: Outcome\n",
      "1    388\n",
      "0    388\n",
      "Name: count, dtype: int64\n",
      "PID onedims:\n",
      "Accuracy: 0.7668\n",
      "Precision: 0.7215\n",
      "Recall: 0.5959\n",
      "F1 Score: 0.6406\n",
      "Prediction time:  1.2105505466461182\n",
      "----------------------------------------------------------------------------------------------\n",
      "PID onedims - Oversampled:\n",
      "Accuracy: 0.8608\n",
      "Precision: 0.8400\n",
      "Recall: 0.8949\n",
      "F1 Score: 0.8656\n",
      "Prediction time:  1.2998974323272705\n",
      "----------------------------------------------------------------------------------------------\n",
      "PID onedims - Hyperparameter Tuning:\n",
      "Best parameters: {'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Best cross-validation accuracy: 0.8673\n",
      "Best cross-validation precision: 0.8717\n",
      "Best cross-validation recall: 0.8674\n",
      "Best cross-validation F1 Score: 0.8668\n",
      "Time for Hypertuning:  20.53564167022705\n",
      "----------------------------------------------------------------------------------------------\n",
      "PID onedims - Predict on testset:\n",
      "\n",
      "Test Set Performance:\n",
      "Accuracy: 0.7384\n",
      "Precision: 0.7132\n",
      "Recall: 0.7179\n",
      "F1 Score: 0.7153\n"
     ]
    }
   ],
   "source": [
    "print(\"----------------------------------------------------------------------------------------------\")\n",
    "print(\"------------------------------------ PIMA INDIANS DIABETES  ----------------------------------\")\n",
    "print(\"----------------------------------------------------------------------------------------------\")\n",
    "print(\"\")\n",
    "\n",
    "print(\"-------------------------------------- ORIGINAL DATASET --------------------------------------\")\n",
    "print(\"----------------------------------------------------------------------------------------------\")\n",
    "PID_train = pd.read_csv(\"C:/Users/ameli/OneDrive/Studium/TU Wien/WS2024/ML/Exercise 3/Datasets/PID_train.csv\")\n",
    "PID_test = pd.read_csv(\"C:/Users/ameli/OneDrive/Studium/TU Wien/WS2024/ML/Exercise 3/Datasets/PID_test.csv\")\n",
    "X_train = PID_train.drop('Outcome', axis=1); y_train = PID_train['Outcome']\n",
    "X_test = PID_test.drop('Outcome', axis=1); y_test = PID_test['Outcome']\n",
    "X_train_oversampled, y_train_oversampled = oversampling(X_train, y_train)\n",
    "\n",
    "print(\"PID:\")\n",
    "rf = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "cross_validate_model(rf, X_train, y_train, cv=5, bivariate = True)\n",
    "\n",
    "print(\"----------------------------------------------------------------------------------------------\")\n",
    "print(\"PID - Oversampled:\")\n",
    "rf = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "cross_validate_model(rf, X_train_oversampled, y_train_oversampled, cv=5, bivariate = True)\n",
    "\n",
    "print(\"----------------------------------------------------------------------------------------------\")\n",
    "print(\"PID - Hyperparameter Tuning:\")\n",
    "best_model, best_params = hyperparameterTuning(X_train_oversampled, y_train_oversampled, cv=5, bivariate = True)\n",
    "\n",
    "print(\"----------------------------------------------------------------------------------------------\")\n",
    "print(\"PID - Predict on testset:\")\n",
    "predict_on_testset(best_model, X_test, y_test)\n",
    "\n",
    "\n",
    "print(\"\")\n",
    "print(\"----------------------------------- AFTER MICROAGGREGATION -----------------------------------\")\n",
    "print(\"----------------------------------------------------------------------------------------------\")\n",
    "\n",
    "print(\"PID - mdav\")\n",
    "PID_train_mdav = pd.read_csv(\"C:/Users/ameli/OneDrive/Studium/TU Wien/WS2024/ML/Exercise 3/modifiedDatasets/PID_mdav.csv\")\n",
    "X_train_mdav = PID_train_mdav.drop('Outcome', axis=1);  y_train_mdav = PID_train_mdav['Outcome']\n",
    "X_train_mdav_oversampled, y_train_mdav_oversampled = oversampling(X_train_mdav, y_train_mdav)\n",
    "\n",
    "print(\"PID MDAV:\")\n",
    "rf = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "cross_validate_model(rf, X_train_mdav, y_train_mdav, cv=5, bivariate = True)\n",
    "\n",
    "print(\"----------------------------------------------------------------------------------------------\")\n",
    "print(\"PID MDAV - Oversampled:\")\n",
    "rf = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "cross_validate_model(rf, X_train_mdav_oversampled, y_train_mdav_oversampled, cv=5, bivariate = True)\n",
    "\n",
    "print(\"----------------------------------------------------------------------------------------------\")\n",
    "print(\"PID MDAV - Hyperparameter Tuning:\")\n",
    "best_model, best_params = hyperparameterTuning(X_train_mdav_oversampled, y_train_mdav_oversampled, cv=5, bivariate = True)\n",
    "\n",
    "print(\"----------------------------------------------------------------------------------------------\")\n",
    "print(\"PID MDAV - Predict on testset:\")\n",
    "predict_on_testset(best_model, X_test, y_test)\n",
    "\n",
    "\n",
    "print(\"PID - PCA\")\n",
    "PID_train_pca = pd.read_csv(\"C:/Users/ameli/OneDrive/Studium/TU Wien/WS2024/ML/Exercise 3/modifiedDatasets/PID_pca.csv\")\n",
    "X_train_pca = PID_train_pca.drop('Outcome', axis=1);  y_train_pca = PID_train_pca['Outcome']\n",
    "X_train_pca_oversampled, y_train_pca_oversampled = oversampling(X_train_pca, y_train_pca)\n",
    "\n",
    "print(\"PID PCA:\")\n",
    "rf = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "cross_validate_model(rf, X_train_pca, y_train_pca, cv=5, bivariate=True)\n",
    "\n",
    "print(\"----------------------------------------------------------------------------------------------\")\n",
    "print(\"PID PCA - Oversampled:\")\n",
    "rf = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "cross_validate_model(rf, X_train_pca_oversampled, y_train_pca_oversampled, cv=5, bivariate=True)\n",
    "\n",
    "print(\"----------------------------------------------------------------------------------------------\")\n",
    "print(\"PID PCA - Hyperparameter Tuning:\")\n",
    "best_model, best_params = hyperparameterTuning(X_train_pca_oversampled, y_train_pca_oversampled, cv=5, bivariate=True)\n",
    "\n",
    "print(\"----------------------------------------------------------------------------------------------\")\n",
    "print(\"PID PCA - Predict on testset:\")\n",
    "predict_on_testset(best_model, X_test, y_test)\n",
    "\n",
    "\n",
    "print(\"PID - onedims\")\n",
    "PID_train_onedims = pd.read_csv(\"C:/Users/ameli/OneDrive/Studium/TU Wien/WS2024/ML/Exercise 3/modifiedDatasets/PID_onedims.csv\")\n",
    "X_train_onedims = PID_train_onedims.drop('Outcome', axis=1);  y_train_onedims = PID_train_onedims['Outcome']\n",
    "X_train_onedims_oversampled, y_train_onedims_oversampled = oversampling(X_train_onedims, y_train_onedims)\n",
    "\n",
    "print(\"PID onedims:\")\n",
    "rf = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "cross_validate_model(rf, X_train_onedims, y_train_onedims, cv=5, bivariate=True)\n",
    "\n",
    "print(\"----------------------------------------------------------------------------------------------\")\n",
    "print(\"PID onedims - Oversampled:\")\n",
    "rf = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "cross_validate_model(rf, X_train_onedims_oversampled, y_train_onedims_oversampled, cv=5, bivariate=True)\n",
    "\n",
    "print(\"----------------------------------------------------------------------------------------------\")\n",
    "print(\"PID onedims - Hyperparameter Tuning:\")\n",
    "best_model, best_params = hyperparameterTuning(X_train_onedims_oversampled, y_train_onedims_oversampled, cv=5, bivariate=True)\n",
    "\n",
    "print(\"----------------------------------------------------------------------------------------------\")\n",
    "print(\"PID onedims - Predict on testset:\")\n",
    "predict_on_testset(best_model, X_test, y_test)\n",
    "\n",
    "print(\"\")\n",
    "print(\"----------------------------------- AFTER GLOBAL TRANSFORMATION -----------------------------------\")\n",
    "print(\"----------------------------------------------------------------------------------------------\")\n",
    "PID_train = pd.read_csv(\"data/PID_train_GT.csv\")\n",
    "PID_test = pd.read_csv(\"data/PID_test_GT.csv\")\n",
    "X_train = PID_train.drop('Outcome', axis=1); y_train = PID_train['Outcome']\n",
    "X_test = PID_test.drop('Outcome', axis=1); y_test = PID_test['Outcome']\n",
    "X_train, X_test = get_dummies_all(X_train, X_test)\n",
    "X_train_oversampled, y_train_oversampled = oversampling(X_train, y_train)\n",
    "\n",
    "print(\"PID Global Transformation:\")\n",
    "rf = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "cross_validate_model(rf, X_train, y_train, cv=5, bivariate = True)\n",
    "\n",
    "print(\"----------------------------------------------------------------------------------------------\")\n",
    "print(\"PID Global Transformation - Oversampled:\")\n",
    "rf = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "cross_validate_model(rf, X_train_oversampled, y_train_oversampled, cv=5, bivariate = True)\n",
    "\n",
    "print(\"----------------------------------------------------------------------------------------------\")\n",
    "print(\"PID Global Transformation - Hyperparameter Tuning:\")\n",
    "best_model, best_params = hyperparameterTuning(X_train, y_train, cv=5, bivariate = True)\n",
    "\n",
    "print(\"----------------------------------------------------------------------------------------------\")\n",
    "print(\"PID Global Transformation - Predict on testset:\")\n",
    "predict_on_testset(best_model, X_test, y_test)\n",
    "\n",
    "\n",
    "print(\"\")\n",
    "print(\"----------------------------------- AFTER LOCAL TRANSFORMATION -----------------------------------\")\n",
    "print(\"----------------------------------------------------------------------------------------------\")\n",
    "PID_train = pd.read_csv(\"data/PID_train_LT.csv\")\n",
    "PID_test = pd.read_csv(\"data/PID_test_LT.csv\")\n",
    "X_train = PID_train.drop('Outcome', axis=1); y_train = PID_train['Outcome']\n",
    "X_test = PID_test.drop('Outcome', axis=1); y_test = PID_test['Outcome']\n",
    "X_train, X_test = get_dummies_all(X_train, X_test)\n",
    "X_train_oversampled, y_train_oversampled = oversampling(X_train, y_train)\n",
    "\n",
    "print(\"PID Global Transformation:\")\n",
    "rf = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "cross_validate_model(rf, X_train, y_train, cv=5, bivariate = True)\n",
    "\n",
    "print(\"----------------------------------------------------------------------------------------------\")\n",
    "print(\"PID Global Transformation - Oversampled:\")\n",
    "rf = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "cross_validate_model(rf, X_train_oversampled, y_train_oversampled, cv=5, bivariate = True)\n",
    "\n",
    "print(\"----------------------------------------------------------------------------------------------\")\n",
    "print(\"PID Global Transformation - Hyperparameter Tuning:\")\n",
    "best_model, best_params = hyperparameterTuning(X_train, y_train, cv=5, bivariate = True)\n",
    "\n",
    "print(\"----------------------------------------------------------------------------------------------\")\n",
    "print(\"PID Global Transformation - Predict on testset:\")\n",
    "predict_on_testset(best_model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"----------------------------------------------------------------------------------------------\")\n",
    "print(\"------------------------------------ CENSUS INCOME  ----------------------------------\")\n",
    "print(\"----------------------------------------------------------------------------------------------\")\n",
    "print(\"\")\n",
    "\n",
    "print(\"\")\n",
    "print(\"----------------------------------- AFTER GLOBAL TRANSFORMATION -----------------------------------\")\n",
    "print(\"----------------------------------------------------------------------------------------------\")\n",
    "KDD_train = pd.read_csv(\"data/KDD_train_GT.csv\")\n",
    "KDD_test = pd.read_csv(\"data/KDD_test_GT.csv\")\n",
    "X_train = KDD_train.drop('income', axis=1); y_train = KDD_train['income']\n",
    "X_test = KDD_test.drop('income', axis=1); y_test = KDD_test['income']\n",
    "le = LabelEncoder()\n",
    "y_train_encoded = le.fit_transform(y_train)\n",
    "y_test_encoded = le.transform(y_test)\n",
    "X_train, X_test = get_dummies_all(X_train, X_test)\n",
    "X_train_oversampled, y_train_oversampled = oversampling(X_train, y_train_encoded)\n",
    "\n",
    "print(\"KDD Global Transformation:\")\n",
    "rf = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "cross_validate_model(rf, X_train, y_train_encoded, cv=3, bivariate = True)\n",
    "\n",
    "print(\"----------------------------------------------------------------------------------------------\")\n",
    "print(\"KDD Global Transformation - Oversampled:\")\n",
    "rf = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "cross_validate_model(rf, X_train_oversampled, y_train_oversampled, cv=3, bivariate = True)\n",
    "\n",
    "print(\"----------------------------------------------------------------------------------------------\")\n",
    "print(\"KDD Global Transformation - Hyperparameter Tuning:\")\n",
    "best_model, best_params = hyperparameterTuning(X_train, y_train_encoded, cv=3, bivariate = True)\n",
    "\n",
    "print(\"----------------------------------------------------------------------------------------------\")\n",
    "print(\"KDD Global Transformation - Predict on testset:\")\n",
    "predict_on_testset(best_model, X_test, y_test_encoded)\n",
    "\n",
    "print(\"\")\n",
    "print(\"----------------------------------- AFTER LOCAL TRANSFORMATION -----------------------------------\")\n",
    "print(\"----------------------------------------------------------------------------------------------\")\n",
    "KDD_train = pd.read_csv(\"data/KDD_train_LT.csv\")\n",
    "KDD_test = pd.read_csv(\"data/KDD_test_LT.csv\")\n",
    "X_train = KDD_train.drop('income', axis=1); y_train = KDD_train['income']\n",
    "X_test = KDD_test.drop('income', axis=1); y_test = KDD_test['income']\n",
    "le = LabelEncoder()\n",
    "y_train_encoded = le.fit_transform(y_train)\n",
    "y_test_encoded = le.transform(y_test)\n",
    "X_train, X_test = get_dummies_all(X_train, X_test)\n",
    "X_train_oversampled, y_train_oversampled = oversampling(X_train, y_train_encoded)\n",
    "\n",
    "print(\"KDD Global Transformation:\")\n",
    "rf = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "cross_validate_model(rf, X_train, y_train_encoded, cv=3, bivariate = True)\n",
    "\n",
    "print(\"----------------------------------------------------------------------------------------------\")\n",
    "print(\"KDD Global Transformation - Oversampled:\")\n",
    "rf = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "cross_validate_model(rf, X_train_oversampled, y_train_oversampled, cv=3, bivariate = True)\n",
    "\n",
    "print(\"----------------------------------------------------------------------------------------------\")\n",
    "print(\"KDD Global Transformation - Hyperparameter Tuning:\")\n",
    "best_model, best_params = hyperparameterTuning(X_train, y_train_encoded, cv=3, bivariate = True)\n",
    "\n",
    "print(\"----------------------------------------------------------------------------------------------\")\n",
    "print(\"KDD Global Transformation - Predict on testset:\")\n",
    "predict_on_testset(best_model, X_test, y_test_encoded)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
